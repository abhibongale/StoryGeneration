{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9117b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import PIL\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a33bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from storygen.config import cfg, cfg_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "089e0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: easydict in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39315c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Flag enabled:  True\n",
      "number of GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "if cfg.CUDA:\n",
    "    print('CUDA Flag enabled: ', cfg.CUDA)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = './output/%s_%s' % (cfg.DATASET_NAME, cfg.CONFIG_NAME)\n",
    "\n",
    "# number of gpus\n",
    "num_gpu = len(cfg.GPU_ID.split(','))\n",
    "print(\"number of GPUs: \", num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600d9a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN FLAG ENABLED: True\n"
     ]
    }
   ],
   "source": [
    "if cfg.TRAIN.FLAG:\n",
    "    print('TRAIN FLAG ENABLED:', cfg.TRAIN.FLAG)\n",
    "    image_transforms = transforms.Compose([PIL.Image.fromarray, \n",
    "                                           transforms.Resize((cfg.IMSIZE, cfg.IMSIZE)),\n",
    "                                           #transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        # dataset = TextDataset(cfg.DATA_DIR, 'train',\n",
    "        #                       imsize=cfg.IMSIZE,\n",
    "        #                       transform=image_transform)\n",
    "        #assert dataset\n",
    "    def video_transform(video, image_transform):\n",
    "        vid = []\n",
    "        for im in video:\n",
    "            vid.append(image_transform(im))\n",
    "        vid = torch.stack(vid).permute(1, 0, 2, 3)\n",
    "        print(\"vid value: \", vid)\n",
    "        return vid\n",
    "\n",
    "    video_len = 5\n",
    "    n_channels = 3\n",
    "    # functools.partial takes methods/functions as an input\n",
    "    video_transforms = functools.partial(video_transform, image_transform=image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd27579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import storygen.pororo_data as data\n",
    "import storygen.train as gan_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e796def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of frames:  183\n",
      "Total number of clips 10191\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"./pororo_data/\"\n",
    "counter = np.load(os.path.join(dir_path, 'frames_counter.npy'), allow_pickle=True).item()\n",
    "print(\"The number of frames: \", len(counter))\n",
    "base = data.VideoFolderDataset(dir_path, counter = counter, cache = dir_path, min_len = 4, mode=\"train\")\n",
    "storydataset = data.StoryDataset(base, dir_path, video_transforms)\n",
    "imagedataset = data.ImageDataset(base, dir_path, image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25a51c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imageloader length:  159\n",
      "storyloader length:  159\n",
      "Total number of clips 2320\n",
      "Validation loader length:  116\n"
     ]
    }
   ],
   "source": [
    "## Train\n",
    "imageloader = torch.utils.data.DataLoader(imagedataset, batch_size=cfg.TRAIN.IM_BATCH_SIZE * num_gpu,\n",
    "                                          drop_last=True, shuffle=True, num_workers=int(cfg.WORKERS))\n",
    "print(\"imageloader length: \", len(imageloader))\n",
    "storyloader = torch.utils.data.DataLoader(storydataset, batch_size=cfg.TRAIN.ST_BATCH_SIZE * num_gpu,\n",
    "                                          drop_last=True, shuffle=True, num_workers=int(cfg.WORKERS))\n",
    "print(\"storyloader length: \", len(storyloader))\n",
    "\n",
    "## Validation\n",
    "val_dir_path = dir_path\n",
    "base_val = data.VideoFolderDataset(val_dir_path, counter, val_dir_path, 4, mode=\"val\")\n",
    "valdataset = data.StoryDataset(base_val, val_dir_path, video_transforms)\n",
    "valloader = torch.utils.data.DataLoader(valdataset, batch_size=20, \n",
    "                                         drop_last=True, shuffle=False, num_workers=int(cfg.WORKERS))\n",
    "print(\"Validation loader length: \", len(valloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db4a0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = gan_train(cfg, output_dir, ratio = 1.0)\n",
    "algo.train(imageloader, storyloader, valloader, cfg.STAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54413ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
